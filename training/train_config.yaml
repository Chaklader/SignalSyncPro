# Training Configuration for DRL Traffic Signal Control

# Environment Settings
environment:
  sumo_config: "test.sumocfg"
  traffic_light_ids: ["3", "6"]
  max_steps_per_episode: 3600  # 1 hour simulation
  
# Network Architecture
network:
  state_dim: null  # Auto-detected from environment
  action_dim: 4
  hidden_layers: [256, 256, 128]
  
# DQN Hyperparameters
dqn:
  learning_rate: 0.0001
  gamma: 0.99
  epsilon_start: 1.0
  epsilon_end: 0.01
  epsilon_decay: 0.995
  tau: 0.005  # Soft update parameter
  
# Replay Buffer
replay_buffer:
  capacity: 100000
  batch_size: 64
  min_buffer_size: 1000
  
# Prioritized Experience Replay
per:
  alpha: 0.6  # Prioritization exponent
  beta_start: 0.4
  beta_frames: 100000
  epsilon: 0.01
  
# Training
training:
  num_episodes: 1000
  update_frequency: 4
  target_update_frequency: 1000
  save_frequency: 50
  
# Reward Function
reward:
  weights:
    waiting_time: 0.1
    emission: 0.05
    synchronization: 5.0
    equity: 2.0
    safety: 100.0
  
  modal_weights:
    car: 1.0
    bicycle: 1.5
    pedestrian: 2.0
    bus: 1.2
    
# Logging
logging:
  log_dir: "logs"
  model_dir: "models"
  tensorboard: true
